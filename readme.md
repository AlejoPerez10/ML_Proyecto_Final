# üß† Proyecto de Modelo Supervisado Predictivo

## Contexto del Proyecto

- En este proyecto trabaj√© en un modelo supervisado para predecir si una persona podr√≠a tener enfermedad card√≠aca o no, usando informaci√≥n cl√≠nica y datos personales de los pacientes. Para esto, us√© el Heart Disease Dataset que saqu√© de Kaggle ```https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset```. Eleg√≠ esta base de datos porque ya hab√≠a trabajado con ella en otro proyecto de programaci√≥n y adem√°s me pareci√≥ muy interesante y √∫nica para este trabajo.

- Durante el desarrollo del proyecto, realic√© varias etapas: primero cargu√© y limpi√© los datos, luego hice un an√°lisis exploratorio para entenderlos mejor, despu√©s constru√≠ nuevas caracter√≠sticas con ingenier√≠a de datos, entren√© y evalu√© varios modelos supervisados, y finalmente desplegu√© el modelo mediante una API. Adem√°s, cre√© una app en Streamlit que permite ver los resultados del modelo de forma gr√°fica y f√°cil de usar.

- El objetivo de todo esto es poder tener un modelo que ayude a predecir el riesgo de enfermedad card√≠aca en pacientes, para que profesionales de la salud o investigadores puedan tomar decisiones m√°s informadas basadas en los datos.

## üìÅ Estructura del Proyecto (completar)

```
ML_Proyecto_Final/
‚îú‚îÄ‚îÄ entorno_ml-venv/                         # Entorno virtual con todas las librer√≠as necesarias.
‚îú‚îÄ‚îÄ mlops_pipeline/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ __pycache__/                     # Archivos compilados de Python para r√°pida ejecuci√≥n.
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ API/                             # Contiene los archivos Docker para la API.
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.api
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.streamlit
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ data/                            # Almacena los datasets y pruebas del modelo.
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ resutls_history/             # historico de resultados guardados con fecha.
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ best_model.pkl               # 
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ feature_list.txt             # 
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.png         # 
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ model_metrics.csv            # 
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ pipeline_preprocessor.pkl    # 
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ results.csv                  # 
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ test.csv                     # 
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ train.csv                    # 
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ Cargar_datos.ipynb               # Carga y preprocesamiento inicial de los datos.
‚îÇ       ‚îú‚îÄ‚îÄ comprension_eda.ipynb            # An√°lisis exploratorio de datos (EDA).
‚îÇ       ‚îú‚îÄ‚îÄ data_loader.py                   # Archivo para cargar una sola vez el df.
‚îÇ       ‚îú‚îÄ‚îÄ ft_engineering.py                # Ingenier√≠a de caracter√≠sticas.
‚îÇ       ‚îú‚îÄ‚îÄ heuristic_model.py               # Modelo base o heur√≠stico para comparaci√≥n.
‚îÇ       ‚îú‚îÄ‚îÄ model_deploy.py                  # Despliegue del modelo.
‚îÇ       ‚îú‚îÄ‚îÄ model_evaluation.ipynb           # Evaluaci√≥n del modelo.
‚îÇ       ‚îú‚îÄ‚îÄ model_monitoring.py              # Entrenamiento del modelo.
‚îÇ       ‚îú‚îÄ‚îÄ model_training_evaluation.py     # Monitoreo del modelo en producci√≥n.
‚îÇ       ‚îú‚îÄ‚îÄ streamlit_app.py                 # Interfaz gr√°fica de mi app.
‚îÇ
‚îú‚îÄ‚îÄ .dockerignore                            # Archivos a ignorar dentro de Docker.
‚îú‚îÄ‚îÄ .gitignore                               # Archivos a ignorar dentro de Git.
‚îú‚îÄ‚îÄ Base_de_datos.csv                        # Fuente principal de datos.
‚îú‚îÄ‚îÄ config.json                              # Configuraciones globales del proyecto.
‚îú‚îÄ‚îÄ readme.md                                # Este archivo.
‚îú‚îÄ‚îÄ requirements.txt                         # Librer√≠as necesarias.
‚îú‚îÄ‚îÄ set_up.bat                               # Script para entorno de ejecuci√≥n en Windows.
```

## Descripci√≥n general del Dataset

- El Heart Disease Dataset proviene de estudios m√©dicos realizados en 1988 en cuatro lugares (Cleveland, Hungr√≠a, Suiza y Long Beach). Contiene informaci√≥n cl√≠nica de pacientes, con 14 atributos m√°s relevantes (como edad, sexo, presi√≥n arterial, colesterol, frecuencia card√≠aca, entre otros).
El objetivo del conjunto de datos es predecir la presencia de una enfermedad card√≠aca, indicada por la variable ‚Äútarget‚Äù (0 = sin enfermedad, 1 = con enfermedad).

### Columnas de mi Dataset

**1-** age `Edad`

**2-** sex `Sexo`

**3-** chest pain type (4 values) `Tipo de dolor en el pecho`
- 0 - Angina T√≠pica
- 1 - Angina At√≠pica
- 2 - Dolor no angionoso
- 3 - Asint√≥matico

**4-** resting blood pressure
   `Presi√≥n arterial en reposo`

**5-** serum cholestoral in mg/dl
   `Colesteron s√©rico`

**6-** fasting blood sugar > 120 mg/dl
   `Az√∫car en ayunas`

**7-** resting electrocardiographic results (values 0,1,2) `Resultados del electrocardiograma en reposo`
- 0 - Normal
- 1 - Anomal√≠a de la onda ST-T
- 2 - Hipertrofia ventricular izquierda

**8-** maximum heart rate achieved
   `Frecuencia cardiaca m√°xima aclanzada`

**9-** exercise induced angina
   `Angina inducida por ejercicio`

**10-** oldpeak = ST depression induced by exercise relative to rest
   `Depresi√≥n del segmenteo ST provocado por ejercicio`

**11-** the slope of the peak exercise ST segment
   `Pendiente del segmento ST`
- 0 - ascendente
- 1 - plano
- 2 - descendente

**12-** number of major vessels (0-3) colored by flourosopy
   `N√∫mero de vasos principales (observados por fluoroscopia)`

**13-** thal: 0 = normal; 1 = fixed defect; 2 = reversable defect
   `Tipo de talsemio o defecto sangu√≠neo`
- 0 - normal
- 1 - defecto fijo (permanente)
- 2 - defecto reversible (mejora con esfuerzo o tratamiento)

**14-** Target `Objetivo`
- 0 - (NO) Enfermedad cardiaca ausente
- 1 - (S√ç) Enfermedad cardiaca presente

### Categor√≠as de las variables

- **`Num√©ricas ‚Üí`** Son cantidades medibles. Se pueden sumar o promediar.
Ej: edad, presi√≥n, colesterol, frecuencia card√≠aca, oldpeak ‚Üí como medir peso o temperatura.

- **`Categ√≥ricas ‚Üí`** Representan grupos o etiquetas, no cantidades.
Ej: sex (h/m), fbs (s√≠/no), exang (s√≠/no), target (enfermo/sano), ca (0‚Äì3 vasos).

- **`Categ√≥ricas nominales ‚Üí`** Son categor√≠as sin orden natural.
Ej: cp, restecg, thal ‚Üí tipos distintos (no mejores ni peores entre s√≠).

- **`Categ√≥rica ordinal ‚Üí`** Son categor√≠as con orden l√≥gico.
Ej: slope (0 ascendente, 1 plana, 2 descendente).

## üêç Entorno Virtual y Activaci√≥n

- Para este proyecto cre√© mi propio entorno virtual con todas las dependencias y librer√≠as necearias para no tener ning√∫n problema a la hora de trabajar con √©l desde un pc remoto, para activarlo haz los siguientes pasos:

1Ô∏è‚É£ Abrir Powershell (terminal) y navegar a la ra√≠z del proyecto.
   ```bash
   cd C:\Users\user\ML_Proyecto_Final
   ```

2Ô∏è‚É£ Ejecutar el setup
   ```bash
   .\set_up.bat
   ```

3Ô∏è‚É£ Ajustar permisos (si es necesario)
   -Solo una vez, si da error al activar el entorno virtual
   ```bash
   Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
   ```

4Ô∏è‚É£ Verificar
   - Activar el entorno:
   ```bash
   .\entorno_ml-venv\Scripts\Activate.ps1
   ```

   - Revisar librer√≠as instaladas:
   ```bash
   pip list
   ```

   - Abrir Jupyter y seleccionar el kernel:
   **entorno_ml-venv Python ETL**

‚ùóDesactivar el entorno
   ```bash
   deactivate
   ```

## Carga de Datos (Cargar_datos.ipynb) y (data_loader.py)
- En este archivo me encargu√© de cargar y revisar el dataset que usar√© en el proyecto. Primero import√© todas las librer√≠as necesarias y luego us√© mi funci√≥n cargar_datos del archivo data_loader.py, que cre√© para no tener que cargar los datos repetidamente y poder usarla donde la necesite.

Verifiqu√© que los datos se cargaran correctamente observando el tama√±o del dataframe y las primeras filas con df.shape y df.head(5). Tambi√©n revis√© los tipos de datos y pude apreciar que en mi dataframe no hab√≠an valores nulos usando df.info() y df.isnull().sum().

Por √∫ltimo, explor√© algunas estad√≠sticas generales con df.describe(include="all").T y not√© que:
*la mayor√≠a de los pacientes tiene alrededor de 54 a√±os, casi el 70 % son hombres, el colesterol promedio es alto (246 mg/dl) y la presi√≥n en reposo tambi√©n elevada (131 mmHg). La frecuencia card√≠aca m√°xima promedio es de 149 bpm y cerca de la mitad de los pacientes presenta riesgo de enfermedad card√≠aca (target ‚âà 0.5). En general, esto refleja una poblaci√≥n adulta con varios indicadores de riesgo cardiovascular.*

## An√°lisis Exploratorio de Datos (comprension_eda.ipynb)
**1. Exploraci√≥n inicial**

Primero revis√© los datos y clasifiqu√© las variables: num√©ricas (age, trestbps, chol, thalach, oldpeak), categ√≥ricas (sex, fbs, exang, target, ca), categ√≥ricas nominales (cp, restecg, thal) y ordinal (slope).

*No encontr√© valores nulos y no hab√≠a columnas irrelevantes, as√≠ que los datos estaban listos para el an√°lisis. Ajust√© los tipos de datos correctamente: num√©ricas a int/float, categ√≥ricas como category y ordinal con su orden l√≥gico.*

**2. An√°lisis univariable**

Revis√© estad√≠sticas descriptivas y visualic√© histogramas, KDE y boxplots:

- Edad: distribuci√≥n centrada en 50‚Äì60 a√±os.

- Presi√≥n y colesterol: algunos outliers, colesterol sesgado a la derecha.

- Frecuencia card√≠aca m√°xima (thalach) y oldpeak: thalach casi normal, oldpeak sesgada.

*En las variables categ√≥ricas, cont√© frecuencias y proporciones: 70% hombres, la mayor√≠a con fbs normal, distribuci√≥n equilibrada de exang, y variabilidad en cp, restecg, thal y slope.*

**3. An√°lisis bivariado**

Revis√© correlaciones entre variables num√©ricas y con el target: thalach y oldpeak resultaron ser los m√°s asociados al target, mientras que edad mostr√≥ relaci√≥n negativa moderada.

*Us√© heatmaps y pairplots para visualizar relaciones y outliers. Boxplots por target confirmaron que thalach y oldpeak son indicadores fuertes. Para las variables categ√≥ricas, hice tablas cruzadas y tests de chi-cuadrado, destacando cp, ca, thal y exang como las m√°s predictivas del target, mientras que fbs no mostr√≥ relaci√≥n significativa.*

**4. An√°lisis multivariado**

Para entender combinaciones de variables, revis√© interacciones entre num√©ricas y categ√≥ricas con respecto al target usando pairplots, scatter plots y tablas cruzadas m√∫ltiples. Not√© patrones interesantes:

- Pacientes m√°s j√≥venes con alta thalach y bajo oldpeak ten√≠an m√°s riesgo.

- Ciertas combinaciones de cp, thal y slope aumentaban claramente la probabilidad de enfermedad.

- Las relaciones entre variables num√©ricas y categ√≥ricas reforzaron la relevancia de las variables que ya hab√≠an destacado en el an√°lisis bivariado.

*En general, este an√°lisis me permiti√≥ entender bien la distribuci√≥n de los datos, detectar relaciones importantes, confirmar qu√© variables podr√≠an ser m√°s relevantes para los modelos, y tambi√©n identificar outliers y patrones que influir√°n en la ingenier√≠a de caracter√≠sticas y el entrenamiento.*

## Ingenier√≠a de Caracter√≠sticas (ft_engineering.py)

En este archivo me encargu√© de preparar los datos para el modelado, generando nuevas caracter√≠sticas, transformando variables y creando un pipeline completo que automatiza todo el proceso.

`Primero cre√© nuevas columnas derivadas para capturar relaciones entre variables, por ejemplo:`

- age_x_thalach = edad √ó frecuencia card√≠aca m√°xima

- thalach_minus_age = frecuencia card√≠aca m√°xima ‚àí edad

- oldpeak_ratio = depresi√≥n del ST / (thalach + 1e-6)

`Luego defin√≠ pipelines para procesar variables num√©ricas y categ√≥ricas:`

- Las num√©ricas se completan con la mediana y se escalan con StandardScaler.

- Las categ√≥ricas se completan con la moda y se codifican con one-hot encoding.

- Divid√≠ los datos en conjuntos de entrenamiento y prueba (estratificando por el target) y apliqu√© un selector de caracter√≠sticas (SelectKBest) para mantener todas las variables, dejando la puerta abierta a futuras mejoras.

`Finalmente, guard√© en mlops_pipeline/src/data:`

- La pipeline completa (pipeline_preprocessor.pkl)

- La lista de features (feature_list.txt)

- Los datasets de entrenamiento y prueba (train.csv y test.csv)

*Con esto, cualquier modelo que entrenemos podr√° usar el mismo procesamiento de datos de forma consistente, asegurando que todas las transformaciones y nuevas variables se apliquen correctamente tanto en entrenamiento como en predicciones futuras.*

`Uso del script`
   ```
   python ft_engineering.py --input ../../Base_de_datos.csv --out_dir ./data --test_size 0.2 --random_state 42
   ```

## Entrenamiento y Evaluaci√≥n de Modelos (model_training_evaluation.py)

En este archivo entren√© y evalu√© distintos modelos supervisados usando los datos procesados en la etapa de ingenier√≠a de caracter√≠sticas.

Primero cargu√© los datasets de entrenamiento y prueba (train.csv y test.csv) y apliqu√© el preprocesamiento guardado en ft_engineering.py para asegurar que todas las transformaciones y nuevas variables se aplicaran de manera consistente.

`Entren√© dos modelos:` (REVISARRRRRRR)

- Logistic Regression

- Random Forest

Para cada modelo, calcul√© m√©tricas de evaluaci√≥n como accuracy, F1-score y ROC-AUC usando la funci√≥n summarize_classification. Luego compar√© los resultados y seleccion√© el modelo con mejor F1-score como el modelo final.

`Guard√© como salida:`

- El modelo seleccionado (best_model.pkl)

- Las m√©tricas de todos los modelos (model_metrics.csv)

- Un gr√°fico comparativo de rendimiento (model_comparison.png)

*Con esto, tengo un modelo entrenado listo para ser usado en predicciones y puedo justificar la elecci√≥n del mejor modelo bas√°ndome en m√©tricas objetivas.*

`Uso del script:`
   ```
   python model_training_evaluation.py --train ./data/train.csv --test ./data/test.csv --out_dir ./data
   ```

## Monitoreo de Datos y Data Drift (model_monitoring.py)

En este archivo me encargu√© de revisar si los datos nuevos se desviaban de los datos de entrenamiento, lo que podr√≠a afectar el desempe√±o del modelo. Para esto, cargu√© los datasets de entrenamiento y prueba, y apliqu√© el mismo preprocesamiento que usamos para entrenar el modelo, asegurando que las transformaciones fueran consistentes.

`Calcul√© varias m√©tricas para detectar Data Drift:`

- Para variables num√©ricas: PSI, KS test, Jensen-Shannon Divergence.

- Para variables categ√≥ricas: Chi-cuadrado.

- Adem√°s, etiquet√© autom√°ticamente los resultados con alertas de riesgo (üü¢ OK, üü° Moderado, ‚ö†Ô∏è Alto) y marqu√© cu√°ndo ser√≠a recomendable un retraining del modelo.

`Guard√© los resultados en:`

- results.csv ‚Üí resumen actual del monitoreo

- results_history/monitoring(fecha).csv ‚Üí hist√≥rico con cada ejecuci√≥n

*Con esto, puedo monitorear cambios en la distribuci√≥n de los datos y detectar desviaciones que puedan afectar la predicci√≥n del modelo. La salida tambi√©n permite tomar decisiones sobre cu√°ndo actualizar o volver a entrenar el modelo.*

`Uso del script:`
   ```
   python model_monitoring.py
   ```

## Despliegue del Modelo (model_deploy.py)

En este archivo desplegu√© el modelo final usando FastAPI para poder realizar predicciones a trav√©s de una API.

`El flujo que implement√© es el siguiente:`

- Carga del modelo (best_model.pkl) y del preprocesador (pipeline_preprocessor.pkl).

- Creaci√≥n de un endpoint /predict que recibe un archivo CSV con nuevos datos y devuelve las predicciones en lote.

- Las predicciones se generan aplicando primero las transformaciones del preprocesador y las nuevas columnas derivadas definidas en ft_engineering.py.

`Tambi√©n inclu√≠ un endpoint / para comprobar que la API funciona correctamente.`

*Con esto, cualquier usuario puede subir un archivo con datos de pacientes y recibir predicciones sobre la probabilidad de enfermedad card√≠aca, lo que facilita la integraci√≥n del modelo en otras aplicaciones o procesos.*

`Uso de la API:`

- Levantar la API
   ```
   ejecutar el script con python model_deploy.py.
   ```

- Enviar un CSV al endpoint /predict para recibir las predicciones.

## Integraci√≥n con SonarCloud

1. Para asegurar la calidad del c√≥digo y la cobertura de pruebas, integr√© el proyecto con SonarCloud, conect√© mi repositorio de GitHub con SonarQube Cloud, permitiendo analizar autom√°ticamente el c√≥digo y los tests.

2. Cre√© pruebas unitarias para los m√≥dulos principales (ft_engineering, model_deploy, model_monitoring, model_training_evaluation) dentro de mlops_pipeline/src/tests.

3. `Ejecut√© las pruebas con cobertura usando:`
   ```
   pytest mlops_pipeline/tests --cov=mlops_pipeline/src --cov-report=xml
   ```

*Esto gener√≥ archivos de cobertura (coverage.xml y .coverage) que SonarCloud usa para evaluar el porcentaje de c√≥digo probado.*

4. Sub√≠ el an√°lisis completo a SonarCloud con:
   ```
   pysonar --sonar-token=<tu-token> --sonar-project-key=AlejoPerez10_ML_Proyecto_Final --sonar-organization=alejoperez10
   ```

*Con esto, puedo revisar m√©tricas de calidad de c√≥digo, vulnerabilidades, duplicaciones y cobertura de pruebas directamente en SonarCloud. Gracias a esta integraci√≥n, garantizo que el c√≥digo cumple con buenas pr√°cticas y que las funciones principales est√°n correctamente testeadas.*

## Despliegue Final en la Web (Docker + Render)

Despu√©s de asegurar la calidad del c√≥digo y la cobertura de pruebas con SonarCloud, proced√≠ a desplegar el modelo y la aplicaci√≥n de manera que pudieran ser usados desde cualquier computadora o ubicaci√≥n remota.

- `Preparaci√≥n de Docker`

Cre√© dos Dockerfiles:

- Dockerfile.api ‚Üí para desplegar la API del modelo (model_deploy.py).

- Dockerfile.streamlit ‚Üí para desplegar la app de Streamlit que permite interactuar con el modelo de forma gr√°fica.

*Cada Dockerfile contiene todas las dependencias necesarias, el c√≥digo fuente y la configuraci√≥n del servidor (Uvicorn para FastAPI y Streamlit para la app).*

- `Construcci√≥n y prueba local`

Constru√≠ las im√°genes Docker con los comandos:
   ```
   docker build -t myapi -f Dockerfile.api .
   ```
   ```
   docker build -t mystreamlit -f Dockerfile.streamlit .
   ```


- Prob√© los contenedores localmente para asegurar que la API y la app funcionaran correctamente antes del despliegue.

- Despliegue en Render

- Sub√≠ las im√°genes Docker a Render, creando servicios separados para la API y la app.

- Esto permiti√≥ que la API y la app est√©n disponibles en la web, accesibles desde cualquier dispositivo sin necesidad de ejecutarlas localmente.

`Resultados`

- La API responde a solicitudes de predicci√≥n v√≠a /predict y puede procesar archivos CSV en lote.

- La app de Streamlit permite visualizar resultados y m√©tricas del modelo de forma interactiva y gr√°fica.

- Gracias a Docker y Render, aseguro disponibilidad, escalabilidad y facilidad de acceso para usuarios remotos.

*Con este paso, el proyecto queda completamente funcional y desplegado en la web, cumpliendo con todos los requisitos de accesibilidad y uso pr√°ctico.*

## Levantar conexi√≥n entre Docker, FastAPI y Streamlit `¬°SOLO PARA ENTORNO LOCAL!`
1- Construir las im√°genes Docker

- FastAPI
   ```
   docker build -t myapi -f mlops_pipeline/src/API/Dockerfile.api .
   ```

- Streamlit
   ```
   docker build -t mystreamlit -f mlops_pipeline/src/API/Dockerfile.streamlit .
   ```

2- Correr los contenedores
   
- FastAPI
   ```
   docker run -p 8000:8000 myapi
   ```

- Streamlit
   ```
   docker run -p 8501:8501 mystreamlit
   ```

3- Probar la APP
   ‚Ä¢ Streamlit: ```http://localhost:8501```
   ‚Ä¢ API FastAPI: ```http://localhost:8000```

4- Para detener los contenedores
   ```
   CTRL + C
   ```

## Ejecutar pruebas unitarias `(en local)`
   ```
   pytest mlops_pipeline/tests --cov=mlops_pipeline/src --cov-report=xml
   ```

## Ejecutar pruebas de SonarQube Cloud `(en local)`
   ```
   pysonar `--sonar-token=671bd2e4a569eb087980ba45285b40cc32db24d9 `--sonar-project-key=AlejoPerez10_ML_Proyecto_Final `--sonar-organization=alejoperez10
   ```